{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsai-praveen/era1-assignments/blob/main/S2/ERA_V1_S2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJptKBxALl-u",
        "outputId": "25b636f3-54f1-4d13-d6f9-41e84ca88399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary # Install torchsummary package"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages such as torch, torchvision, torchsummary\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "0ccVrMUtdXAS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA (GPU) is available. Set the device accordingly\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Owi1LBNY8L",
        "outputId": "23ed46f3-26fb-46f5-fd44-9da58a226c0e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the batch size to 128, meaning there will be 128 images per batch\n",
        "batch_size = 128\n",
        "\n",
        "# Create the train loader, load the MNIST dataset (lazy load happens here)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True, # Save to data folder, download train data\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(), # Normalize the data between 0 - 1\n",
        "                        transforms.Normalize((0.1307,), (0.3081,)) # Standardize the data so that mean is 0 and standard deviation is 1\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Create the train loader, load the MNIST test dataset (lazy load happens here)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False,  # Save to data folder, indicate test data\n",
        "                        transform=transforms.Compose([\n",
        "                        transforms.ToTensor(), # Normalize the data between 0 - 1\n",
        "                        transforms.Normalize((0.1307,), (0.3081,)) # Standardize the data so that mean is 0 and standard deviation is 1\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "EQZaZRGcNLtr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Notes on our naive model\n",
        "\n",
        "We are going to write a network based on what we have learnt so far. \n",
        "\n",
        "The size of the input image is 28x28x1. We are going to add as many layers as required to reach RF = 32 \"atleast\". "
      ],
      "metadata": {
        "id": "r3gEjf-xMb-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstDNN(nn.Module):\n",
        "  # Define various convolution layers\n",
        "  def __init__(self):\n",
        "    super(FirstDNN, self).__init__()\n",
        "    # r_in:1, n_in:28, j_in:1, s:1, r_out:3, n_out:28, j_out:1\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "    # r_in:3 , n_in:28 , j_in:1 , s:1 , r_out:5 , n_out:28 , j_out:1\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    # r_in:5 , n_in:28 , j_in:1 , s:2 , r_out:6 , n_out:14 , j_out:2\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "    # r_in:6 , n_in:14 , j_in:2 , s:1 , r_out:10 , n_out:14 , j_out:2\n",
        "    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "    # r_in:10 , n_in:14 , j_in:2 , s:1 , r_out:14 , n_out:14 , j_out:2\n",
        "    self.conv4 = nn.Conv2d(128, 256, 3, padding = 1)\n",
        "    # r_in:14 , n_in:14 , j_in:2 , s:2 , r_out:16 , n_out:7 , j_out:4\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    # r_in:16 , n_in:7 , j_in:4 , s:1 , r_out:24 , n_out:5, j_out:4\n",
        "    self.conv5 = nn.Conv2d(256, 512, 3)\n",
        "    # r_in:24 , n_in:5 , j_in:4 , s:1 , r_out:32 , n_out:3 , j_out:4\n",
        "    self.conv6 = nn.Conv2d(512, 1024, 3)\n",
        "    # r_in:32 , n_in:3 , j_in:4 , s:1 , r_out:40 , n_out:1 , j_out:4\n",
        "    self.conv7 = nn.Conv2d(1024, 10, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x is the input image. Feed it to conv1 layer, ReLU on top of it. After 2 such layers, add a maxpool layer on top\n",
        "    x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "    # Repeat the steps again for conv3, conv4, pool2\n",
        "    x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "    # Repeat for conv5 & 6\n",
        "    x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "    # The final output layer, ReLU should not be there.\n",
        "    # x = F.relu(self.conv7(x))\n",
        "    x = self.conv7(x)\n",
        "    x = x.view(-1, 10) # reshape the data\n",
        "    return F.log_softmax(x) # Return the log softmax of the value\n"
      ],
      "metadata": {
        "id": "Sir2LmSVLr_4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the neural network and port it to GPU\n",
        "model = FirstDNN().to(device)"
      ],
      "metadata": {
        "id": "sxICO4TTNt2H"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model summary\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M__MtFIYNwXa",
        "outputId": "68dfc1e7-6ccf-4e33-efb6-d514fed6573c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
            "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
            "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
            "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
            "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
            "================================================================\n",
            "Total params: 6,379,786\n",
            "Trainable params: 6,379,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.51\n",
            "Params size (MB): 24.34\n",
            "Estimated Total Size (MB): 25.85\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-a2e90ce19174>:35: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x) # Return the log softmax of the value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Function for training\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train() # Set the model to train mode\n",
        "    pbar = tqdm(train_loader) # Create a tqdm iterator\n",
        "    for batch_idx, (data, target) in enumerate(pbar): # Run for every batch\n",
        "        data, target = data.to(device), target.to(device) # Port data to GPU\n",
        "        optimizer.zero_grad() # Reset any previous gradient to zero\n",
        "        output = model(data) # Call the model\n",
        "        loss = F.nll_loss(output, target) # Calculate the negative log likelihood\n",
        "        loss.backward() # Compute the gradients\n",
        "        optimizer.step() # Backpropogate the gradients\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}') # Prints out the status\n",
        "\n",
        "# Function for testing\n",
        "def test(model, device, test_loader):\n",
        "    model.eval() # Set the model mode to eval\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad(): # Turn off gradient accumulation\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device) # Port data to GPU\n",
        "            output = model(data) # Call the model\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item() # Calculate how many of them are correct in that batch\n",
        "\n",
        "    test_loss /= len(test_loader.dataset) # Get the average test loss\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "g_vlC-bdNzo1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # Create a Schocastic Gradient Descent optimizer with lr as 0.01 and momentum 0.9. MomentMomentum helps with early convergence.\n",
        "\n",
        "for epoch in range(1, 2):\n",
        "    # Train the model on the device for number of epochs. Get data using train_loader. Use optimizer\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    # Test the model\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgQ1DtOY0JtT",
        "outputId": "0f1fe8b2-e382-4b84-c262-1c93ee2eac8e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]<ipython-input-22-a2e90ce19174>:35: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x) # Return the log softmax of the value\n",
            "loss=0.28070756793022156 batch_id=468: 100%|██████████| 469/469 [00:30<00:00, 15.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3318, Accuracy: 8656/10000 (87%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # Create a Schocastic Gradient Descent optimizer with lr as 0.01 and momentum 0.9. MomentMomentum helps with early convergence.\n",
        "\n",
        "for epoch in range(1, 2):\n",
        "    # Train the model on the device for number of epochs. Get data using train_loader. Use optimizer\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    # Test the model\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDPylku1z8bt",
        "outputId": "bad611dc-29d2-4317-f1c9-a5dd9560895d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]<ipython-input-16-ba9276a8bf98>:35: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x) # Return the log softmax of the value\n",
            "loss=0.006621516775339842 batch_id=468: 100%|██████████| 469/469 [00:31<00:00, 14.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0297, Accuracy: 9904/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # Create a Schocastic Gradient Descent optimizer with lr as 0.01 and momentum 0.9. MomentMomentum helps with early convergence.\n",
        "\n",
        "for epoch in range(0, 4):\n",
        "    # Train the model on the device for number of epochs. Get data using train_loader. Use optimizer\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    # Test the model\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0FYVWkGOFBS",
        "outputId": "accc29d3-d8b5-4216-9e5f-c4943e8ea99e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]<ipython-input-16-ba9276a8bf98>:35: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x) # Return the log softmax of the value\n",
            "loss=0.06502588838338852 batch_id=468: 100%|██████████| 469/469 [00:29<00:00, 15.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0537, Accuracy: 9825/10000 (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.014189152978360653 batch_id=468: 100%|██████████| 469/469 [00:30<00:00, 15.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0418, Accuracy: 9864/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.009600267745554447 batch_id=468: 100%|██████████| 469/469 [00:30<00:00, 15.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0284, Accuracy: 9905/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.0068410951644182205 batch_id=468: 100%|██████████| 469/469 [00:29<00:00, 15.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0291, Accuracy: 9901/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "reIBU667OG_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}